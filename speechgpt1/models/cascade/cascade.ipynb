{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AsrLlmCascadeModel(\n",
       "  (asr): HuggingFaceWhisperModel(\n",
       "    (encoder): DummyEncoder()\n",
       "    (decoder): DummyDecoder()\n",
       "    (model): WhisperForConditionalGeneration(\n",
       "      (model): WhisperModel(\n",
       "        (encoder): WhisperEncoder(\n",
       "          (conv1): Conv1d(128, 1280, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (conv2): Conv1d(1280, 1280, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "          (embed_positions): Embedding(1500, 1280)\n",
       "          (layers): ModuleList(\n",
       "            (0-31): 32 x WhisperEncoderLayer(\n",
       "              (self_attn): WhisperSdpaAttention(\n",
       "                (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              )\n",
       "              (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (activation_fn): GELUActivation()\n",
       "              (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "              (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "              (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (decoder): WhisperDecoder(\n",
       "          (embed_tokens): Embedding(51866, 1280, padding_idx=50257)\n",
       "          (embed_positions): WhisperPositionalEmbedding(448, 1280)\n",
       "          (layers): ModuleList(\n",
       "            (0-3): 4 x WhisperDecoderLayer(\n",
       "              (self_attn): WhisperSdpaAttention(\n",
       "                (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              )\n",
       "              (activation_fn): GELUActivation()\n",
       "              (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (encoder_attn): WhisperSdpaAttention(\n",
       "                (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "                (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              )\n",
       "              (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "              (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "              (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (proj_out): Linear(in_features=1280, out_features=51866, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (llm): HuggingFaceQwen2ForCausalLM(\n",
       "    (decoder): Qwen2Decoder(\n",
       "      (embed_tokens): Embedding(151936, 896)\n",
       "      (layers): ModuleList(\n",
       "        (0-23): 24 x Qwen2DecoderLayer(\n",
       "          (self_attn): Qwen2Attention(\n",
       "            (q_proj): Linear(in_features=896, out_features=896, bias=True)\n",
       "            (k_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "            (v_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "            (o_proj): Linear(in_features=896, out_features=896, bias=False)\n",
       "            (rotary_emb): Qwen2RotaryEmbedding()\n",
       "          )\n",
       "          (mlp): Qwen2MLP(\n",
       "            (gate_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "            (up_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "            (down_proj): Linear(in_features=4864, out_features=896, bias=False)\n",
       "            (act_fn): SiLU()\n",
       "          )\n",
       "          (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "          (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "        )\n",
       "      )\n",
       "      (norm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "      (rotary_emb): Qwen2RotaryEmbedding()\n",
       "    )\n",
       "    (lm_head): Linear(in_features=896, out_features=151936, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from omegaconf import OmegaConf\n",
    "from model import AsrLlmCascadeModel\n",
    "\n",
    "args = OmegaConf.create()\n",
    "args.llm_config = \"Qwen/Qwen2-0.5B\"\n",
    "args.asr_config = \"openai/whisper-large-v3-turbo\"\n",
    "\n",
    "cascade = AsrLlmCascadeModel.build_model(args)\n",
    "cascade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_cyESGHlEgnM"
   },
   "source": [
    "# Тесты, что работает"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "WnvxIl1Gw4s6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-05 18:59:43 | INFO | datasets | PyTorch version 2.5.1 available.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import soundfile as sf\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "dataset = load_dataset(\"distil-whisper/librispeech_long\", \"clean\", split=\"validation\")\n",
    "sample = dataset[0][\"audio\"]\n",
    "\n",
    "waveform = torch.tensor(sample['array']).unsqueeze(0)  # Add batch dimension\n",
    "sampling_rate = sample['sampling_rate']\n",
    "\n",
    "waveform = waveform.float()\n",
    "\n",
    "inputs = cascade.asr.processor(waveform.squeeze(0), sampling_rate=sampling_rate, return_tensors=\"pt\")\n",
    "waveform = inputs['input_features']\n",
    "\n",
    "sf.write('audio.wav', sample['array'], sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dOrhG4v5w4wV",
    "outputId": "31f0312c-ca0a-4ab7-c54a-69b1d5b82491"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.43.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[50258, 50259, 50360, 50364,  2221,    13,  2326,   388,   391,   307,\n",
       "           264, 50244,   295,   264,  2808,  5359,    11,   293,   321,   366,\n",
       "          5404,   281,  2928,   702, 14943,    13,  6966,   307,  2221,    13,\n",
       "          2326,   388,   391,   311,  9060,  1570,  1880,   813,   702,  1871,\n",
       "            13,   634,  5112,   505,   300,   412,   341, 42729,  3196,   295,\n",
       "           264,  1064,    11,   365,  5272,   293, 12904,  9256,   450, 10539,\n",
       "           949,   505,    11,  1034,  4680, 10117,   490,  3936,   293,  1080,\n",
       "          3542,  5160,   881, 26336,   281,   264,  1575,    13,   634,   575,\n",
       "         12525, 22618,  1968,  6144, 35617, 20084,  1756,   311,   589,   307,\n",
       "           534, 10281,   934,   439,    11]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # 1. сгенерировать токены\n",
    "\n",
    "cascade.generate_from_asr(waveform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fXHz1DxnDr-a",
    "outputId": "3cfaebbd-6d99-40b8-9155-e72a3119859e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\" Mr. Quilter is the apostle of the middle classes, and we are glad to welcome his gospel. Nor is Mr. Quilter's manner less interesting than his matter. He tells us that at this festive season of the year, with Christmas and roast beef looming before us, similes drawn from eating and its results occur most readily to the mind. He has grave doubts whether Sir Frederick Layton's work is really Greek after all,\"]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. сгенерировать текст\n",
    "\n",
    "cascade.generate_from_asr(waveform, text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nz63pUNKD6k8",
    "outputId": "caab4185-6d0e-432d-8d11-9e2fae2b9056"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[50258, 50259, 50360, 50364,  2221,    13,  2326,   388,   391,   307,\n",
       "           264, 50244,   295,   264,  2808,  5359,    11,   293,   321,   366,\n",
       "          5404,   281,  2928,   702, 14943,    13,  6966,   307,  2221,    13,\n",
       "          2326,   388,   391,   311,  9060,  1570,  1880,   813,   702,  1871,\n",
       "            13,   634,  5112,   505,   300,   412,   341, 42729,  3196,   295,\n",
       "           264,  1064,    11,   365,  5272,   293, 12904,  9256,   450, 10539,\n",
       "           949,   505,    11,  1034,  4680, 10117,   490,  3936,   293,  1080,\n",
       "          3542,  5160,   881, 26336,   281,   264,  1575,    13,   634,   575,\n",
       "         12525, 22618,  1968,  6144, 35617, 20084,  1756,   311,   589,   307,\n",
       "           534, 10281,   934,   439,    11]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. сгенерировать токены из аудиофайла\n",
    "\n",
    "cascade.generate_from_asr(file='audio.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "szXmyx-zD4vS",
    "outputId": "38bdc83c-4605-4cfb-a18f-2623129db679"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\" Mr. Quilter is the apostle of the middle classes, and we are glad to welcome his gospel. Nor is Mr. Quilter's manner less interesting than his matter. He tells us that at this festive season of the year, with Christmas and roast beef looming before us, similes drawn from eating and its results occur most readily to the mind. He has grave doubts whether Sir Frederick Layton's work is really Greek after all,\"]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. сгенерировать из текст аудиофайла\n",
    "\n",
    "cascade.generate_from_asr(file='audio.wav', text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S2jGeV7pD1qE",
    "outputId": "5ce6cc6b-ba24-4996-8040-a44d36ecc243"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[50258, 50259, 50360, 50364,  2221,    13,  2326,   388,   391,   307,\n",
       "            264, 50244,   295,   264,  2808,  5359,    11,   293,   321,   366,\n",
       "           5404,   281,  2928,   702, 14943,    13,  6966,   307,  2221,    13,\n",
       "           2326,   388,   391,   311,  9060,  1570,  1880,   813,   702,  1871,\n",
       "             13,   634,  5112,   505,   300,   412,   341, 42729,  3196,   295,\n",
       "            264,  1064,    11,   365,  5272,   293, 12904,  9256,   450, 10539,\n",
       "            949,   505,    11,  1034,  4680, 10117,   490,  3936,   293,  1080,\n",
       "           3542,  5160,   881, 26336,   281,   264,  1575,    13,   634,   575,\n",
       "          12525, 22618,  1968,  6144, 35617, 20084,  1756,   311,   589,   307,\n",
       "            534, 10281,   934,   439,    11]]),\n",
       " None,\n",
       " None,\n",
       " None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. форвард пасс\n",
    "\n",
    "in_features = cascade.asr.processor(sample[\"array\"], sampling_rate=sample[\"sampling_rate\"], return_tensors=\"pt\").input_features\n",
    "prompt_ids = torch.tensor(cascade.asr.processor.tokenizer.prefix_tokens).unsqueeze(0)\n",
    "cascade(src_tokens=in_features, tgt_tokens=prompt_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\speechgpt\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Mr. Quilter is the apostle of the middle classes, and we are glad to welcome his gospel. Nor is Mr. Quilter's manner less interesting than his matter. He tells us that at this festive season of the year, with Christmas and roast beef looming before us, similes drawn from eating and its results occur most readily to the mind. He has grave doubts whether Sir Frederick Layton's work is really Greek after all, though it is certainly French. The fact is that it is not the work of a Frenchman but is the result of the thinking of a man from America, so that it is no more foreign to us than French to anyone, but no less strange to us. It is true that one may take his work as a whole, but, in the light of our observations above, it is impossible to imagine it as being anything but strange to us. He has a strange view of the subject of the work, and the peculiar difficulties of its presentation he has experienced himself. In his opening sentence he says that it is to some extent 'a thing of Greek origin.' He then makes a full and full statement of the Greek character, which must be very\n",
      "_________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 6. Ответ LLM по аудио\n",
    "\n",
    "gen_texts = cascade.generate(file='audio.wav', max_new_tokens=150, do_sample=True, top_k=50, top_p=0.95)\n",
    "for _ in gen_texts:\n",
    "    print(_)\n",
    "    print(\"_________________________________________________\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
